{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:04.547612Z",
     "start_time": "2019-04-10T15:31:23.517647Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchsample as ts\n",
    "from torchsample.transforms import RandomRotate\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:09.206463Z",
     "start_time": "2019-04-10T15:32:09.181447Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_files,transform):\n",
    "        super().__init__()\n",
    "        self.csv_files=csv_files\n",
    "        with open(csv_files[0], 'rb') as f:\n",
    "            X = np.array(pickle.load(f),dtype=np.float32)\n",
    "        \n",
    "        if csv_files[1] is not None:\n",
    "            with open(csv_files[1], 'rb') as g:\n",
    "                y = np.array(pickle.load(g))\n",
    "            le=LabelEncoder()\n",
    "            y_label=le.fit_transform(y)\n",
    "            self.y=y_label\n",
    "            self.le =le \n",
    "            \n",
    "        self.transform=transform\n",
    "        \n",
    "        self.X= X.reshape(-1,1,28,28)\n",
    "#         self.X= X.reshape(-1,1,28,28)\n",
    "#         print(np.mean(np.mean(self.X,axis=0)))\n",
    "              \n",
    "                \n",
    "    def get_class_count(self):\n",
    "        return len(self.le.classes_)\n",
    "    \n",
    "    def get_input_dim(self):\n",
    "        return self.X.shape[1]\n",
    "    \n",
    "    def get_class_labels(self,y_label):\n",
    "        le=self.le\n",
    "        return le.inverse_transform(y_label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "         z=self.X[idx]\n",
    "         #print(z.shape)\n",
    "         z=np.reshape(z, (28,28))\n",
    "         img_name = Image.fromarray(z)\n",
    "#         plt.imshow(img_name)\n",
    "         sample=self.X[idx]\n",
    "        \n",
    "         if self.transform is not None:\n",
    "            sample = self.transform(img_name)\n",
    "#             #plt.show()\n",
    "            sample= sample.reshape(1,28,28)         \n",
    "            return sample,self.y[idx]\n",
    "         \n",
    "         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:12.243719Z",
     "start_time": "2019-04-10T15:32:11.516401Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_size=0.3\n",
    "shuffle=True\n",
    "valid_transform = transforms.Compose([transforms.ToTensor(),  transforms.Normalize(mean=[82.34472], std=[255]),])\n",
    "\n",
    "augment_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomAffine(30), transforms.ToTensor(),  transforms.Normalize(mean=[82.34472], std=[255]),])\n",
    "train_transform = transforms.Compose([ transforms.ToTensor(),  transforms.Normalize(mean=[82.34472], std=[255]),])\n",
    "\n",
    "train_dataset = ImageDataset(['train_image.pkl','train_label.pkl'],train_transform)\n",
    "valid_dataset = ImageDataset(['train_image.pkl','train_label.pkl'],valid_transform)\n",
    "augment_dataset = ImageDataset(['train_image.pkl','train_label.pkl'],augment_transform)\n",
    "#test_dataset = ImageDataset(['test_image.pkl', None],transforms.ToTensor())\n",
    "batch_size=512\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "if shuffle:\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "augment_loader = torch.utils.data.DataLoader(augment_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:14.348422Z",
     "start_time": "2019-04-10T15:32:14.345419Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:17.414417Z",
     "start_time": "2019-04-10T15:32:17.389400Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batch1=nn.BatchNorm2d(32)\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batch2=nn.BatchNorm2d(64)\n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "#         self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.batch3=nn.BatchNorm2d(64)\n",
    "#         # Max pool 3\n",
    "#         self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64 * 4 * 4, out_features=60)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.outer = nn.Linear(in_features=60, out_features=4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Convolution 1\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.batch1(out)\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Convolution 2 \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.batch2(out)\n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "#         # Convolution 3 \n",
    "#         out = self.conv3(out)\n",
    "#         out = self.relu3(out)\n",
    "#         out = self.batch3(out)\n",
    "#         # Max pool 3 \n",
    "#         out = self.maxpool3(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        #out = self.fc2(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.outer(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:19.957428Z",
     "start_time": "2019-04-10T15:32:19.933399Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Network().cuda(1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-10T10:02:26.522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Training_Loss: 1.1544707380235195.Testing_Loss:1.0520039558410645. Accuracy: 46\n",
      "Epoch: 2. Training_Loss: 0.6390603668987751.Testing_Loss:0.6012688398361206. Accuracy: 73\n",
      "Epoch: 4. Training_Loss: 0.5400331486016512.Testing_Loss:0.5396576702594758. Accuracy: 80\n",
      "Epoch: 6. Training_Loss: 0.5067481156438589.Testing_Loss:0.4374894917011261. Accuracy: 83\n",
      "Epoch: 8. Training_Loss: 0.4857434891164303.Testing_Loss:0.5048968195915222. Accuracy: 78\n",
      "Epoch: 10. Training_Loss: 0.44428982585668564.Testing_Loss:0.45414952039718626. Accuracy: 82\n",
      "Epoch: 12. Training_Loss: 0.4141511507332325.Testing_Loss:0.4457251846790314. Accuracy: 83\n",
      "Epoch: 14. Training_Loss: 0.43014665972441435.Testing_Loss:0.4082306087017059. Accuracy: 84\n",
      "Epoch: 16. Training_Loss: 0.4098108056932688.Testing_Loss:0.3806808054447174. Accuracy: 85\n",
      "Epoch: 18. Training_Loss: 0.4166389349848032.Testing_Loss:0.3901773691177368. Accuracy: 84\n",
      "Epoch: 20. Training_Loss: 0.36805864702910185.Testing_Loss:0.3574111878871918. Accuracy: 86\n",
      "Epoch: 22. Training_Loss: 0.3542820354923606.Testing_Loss:0.3280540108680725. Accuracy: 86\n",
      "Epoch: 24. Training_Loss: 0.355398029088974.Testing_Loss:0.39906070232391355. Accuracy: 84\n",
      "Epoch: 26. Training_Loss: 0.32399834133684635.Testing_Loss:0.34341949224472046. Accuracy: 86\n",
      "Epoch: 28. Training_Loss: 0.2920223409309983.Testing_Loss:0.3235593974590302. Accuracy: 87\n",
      "Epoch: 30. Training_Loss: 0.2693017777055502.Testing_Loss:0.3326404392719269. Accuracy: 87\n",
      "Epoch: 32. Training_Loss: 0.2738968664780259.Testing_Loss:0.34634113907814024. Accuracy: 86\n",
      "Epoch: 34. Training_Loss: 0.2810175255872309.Testing_Loss:0.2926027327775955. Accuracy: 89\n",
      "Epoch: 36. Training_Loss: 0.2903857119381428.Testing_Loss:0.2833442449569702. Accuracy: 88\n",
      "Epoch: 38. Training_Loss: 0.25203390000388026.Testing_Loss:0.31355361342430116. Accuracy: 87\n",
      "Epoch: 40. Training_Loss: 0.27411630703136325.Testing_Loss:0.31853899359703064. Accuracy: 87\n",
      "Epoch: 42. Training_Loss: 0.24954808223992586.Testing_Loss:0.3010754883289337. Accuracy: 88\n",
      "Epoch: 44. Training_Loss: 0.24170112097635865.Testing_Loss:0.29300807118415834. Accuracy: 89\n",
      "Epoch: 46. Training_Loss: 0.22132296906784177.Testing_Loss:0.3011252224445343. Accuracy: 88\n",
      "Epoch: 48. Training_Loss: 0.25939243473112583.Testing_Loss:0.2998655140399933. Accuracy: 88\n",
      "Epoch: 50. Training_Loss: 0.2072731964290142.Testing_Loss:0.29607032239437103. Accuracy: 89\n",
      "Epoch: 52. Training_Loss: 0.2434008689597249.Testing_Loss:0.333227276802063. Accuracy: 87\n",
      "Epoch: 54. Training_Loss: 0.27317477855831385.Testing_Loss:0.31922886967659. Accuracy: 88\n",
      "Epoch: 56. Training_Loss: 0.26685045240446925.Testing_Loss:0.3223405957221985. Accuracy: 88\n",
      "Epoch: 58. Training_Loss: 0.22592778969556093.Testing_Loss:0.2664991766214371. Accuracy: 89\n",
      "Epoch: 60. Training_Loss: 0.21156249335035682.Testing_Loss:0.2538780361413956. Accuracy: 89\n",
      "Epoch: 62. Training_Loss: 0.26652445178478956.Testing_Loss:0.3807157397270203. Accuracy: 85\n",
      "Epoch: 64. Training_Loss: 0.19555258192121983.Testing_Loss:0.2618780374526978. Accuracy: 90\n",
      "Epoch: 66. Training_Loss: 0.22283646557480097.Testing_Loss:0.26466684639453886. Accuracy: 89\n",
      "Epoch: 68. Training_Loss: 0.21796281286515296.Testing_Loss:0.3130420446395874. Accuracy: 89\n",
      "Epoch: 70. Training_Loss: 0.18031258485279977.Testing_Loss:0.2766530752182007. Accuracy: 89\n",
      "Epoch: 72. Training_Loss: 0.17364577134139836.Testing_Loss:0.24923412203788758. Accuracy: 91\n",
      "Epoch: 74. Training_Loss: 0.22049408219754696.Testing_Loss:0.2629512459039688. Accuracy: 89\n",
      "Epoch: 76. Training_Loss: 0.1867187051102519.Testing_Loss:0.2794734388589859. Accuracy: 89\n",
      "Epoch: 78. Training_Loss: 0.17482615541666746.Testing_Loss:0.2280398577451706. Accuracy: 91\n",
      "Epoch: 80. Training_Loss: 0.19249356747604907.Testing_Loss:0.28034777045249937. Accuracy: 90\n",
      "Epoch: 82. Training_Loss: 0.18170097307302058.Testing_Loss:0.26495741307735443. Accuracy: 89\n",
      "Epoch: 84. Training_Loss: 0.17602477758191526.Testing_Loss:0.20376569032669067. Accuracy: 91\n",
      "Epoch: 86. Training_Loss: 0.2029027072712779.Testing_Loss:0.28459464609622953. Accuracy: 89\n",
      "Epoch: 88. Training_Loss: 0.16388138523325324.Testing_Loss:0.2351682722568512. Accuracy: 91\n",
      "Epoch: 90. Training_Loss: 0.16039644018746912.Testing_Loss:0.24573304653167724. Accuracy: 90\n",
      "Epoch: 92. Training_Loss: 0.15823840885423124.Testing_Loss:0.23749880790710448. Accuracy: 90\n",
      "Epoch: 94. Training_Loss: 0.1964181731455028.Testing_Loss:0.2433678239583969. Accuracy: 89\n",
      "Epoch: 96. Training_Loss: 0.16690837778151035.Testing_Loss:0.21630861461162568. Accuracy: 91\n",
      "Epoch: 98. Training_Loss: 0.17454374162480235.Testing_Loss:0.2226318895816803. Accuracy: 91\n",
      "Epoch: 100. Training_Loss: 0.16316391807049513.Testing_Loss:0.26810204386711123. Accuracy: 90\n",
      "Epoch: 102. Training_Loss: 0.15079465368762612.Testing_Loss:0.18215823769569398. Accuracy: 93\n",
      "Epoch: 104. Training_Loss: 0.1518308410886675.Testing_Loss:0.17287744879722594. Accuracy: 93\n",
      "Epoch: 106. Training_Loss: 0.14601636910811067.Testing_Loss:0.25115072131156924. Accuracy: 90\n",
      "Epoch: 108. Training_Loss: 0.14534068224020302.Testing_Loss:0.2054855227470398. Accuracy: 92\n",
      "Epoch: 110. Training_Loss: 0.12318350048735738.Testing_Loss:0.21437167823314668. Accuracy: 92\n",
      "Epoch: 112. Training_Loss: 0.14027333911508322.Testing_Loss:0.19428727328777312. Accuracy: 92\n",
      "Epoch: 114. Training_Loss: 0.14603854494635016.Testing_Loss:0.19100367426872253. Accuracy: 92\n",
      "Epoch: 116. Training_Loss: 0.14919572044163942.Testing_Loss:0.1720320075750351. Accuracy: 92\n",
      "Epoch: 118. Training_Loss: 0.1667797693517059.Testing_Loss:0.22025724351406098. Accuracy: 91\n",
      "Epoch: 120. Training_Loss: 0.14261112292297184.Testing_Loss:0.18687972128391267. Accuracy: 92\n",
      "Epoch: 122. Training_Loss: 0.12843262834940106.Testing_Loss:0.1912938266992569. Accuracy: 92\n",
      "Epoch: 124. Training_Loss: 0.1308449312346056.Testing_Loss:0.172556734085083. Accuracy: 93\n",
      "Epoch: 126. Training_Loss: 0.15119330305606127.Testing_Loss:0.17787352800369263. Accuracy: 93\n",
      "Epoch: 128. Training_Loss: 0.11949045886285603.Testing_Loss:0.1859922841191292. Accuracy: 92\n",
      "Epoch: 130. Training_Loss: 0.13605992833618075.Testing_Loss:0.15472496449947357. Accuracy: 94\n",
      "Epoch: 132. Training_Loss: 0.13551521371118724.Testing_Loss:0.17674356698989868. Accuracy: 93\n",
      "Epoch: 134. Training_Loss: 0.12396185123361647.Testing_Loss:0.20323565900325774. Accuracy: 91\n",
      "Epoch: 136. Training_Loss: 0.12537455459823832.Testing_Loss:0.1456741899251938. Accuracy: 94\n",
      "Epoch: 138. Training_Loss: 0.1340775719145313.Testing_Loss:0.16507258415222167. Accuracy: 93\n",
      "Epoch: 140. Training_Loss: 0.11384164448827505.Testing_Loss:0.17945920526981354. Accuracy: 93\n",
      "Epoch: 142. Training_Loss: 0.13202992524020374.Testing_Loss:0.15405020415782927. Accuracy: 93\n",
      "Epoch: 144. Training_Loss: 0.13759927975479513.Testing_Loss:0.2296602636575699. Accuracy: 91\n",
      "Epoch: 146. Training_Loss: 0.12904796027578413.Testing_Loss:0.19956018924713134. Accuracy: 93\n",
      "Epoch: 148. Training_Loss: 0.13774771988391876.Testing_Loss:0.17267144322395325. Accuracy: 93\n",
      "Epoch: 150. Training_Loss: 0.14147344324737787.Testing_Loss:0.20559405386447907. Accuracy: 92\n",
      "Epoch: 152. Training_Loss: 0.1277033113874495.Testing_Loss:0.16350529491901397. Accuracy: 93\n",
      "Epoch: 154. Training_Loss: 0.12002314243000001.Testing_Loss:0.15631358921527863. Accuracy: 93\n",
      "Epoch: 156. Training_Loss: 0.11135114834178239.Testing_Loss:0.15934441983699799. Accuracy: 94\n",
      "Epoch: 158. Training_Loss: 0.13336650317069143.Testing_Loss:0.17638106644153595. Accuracy: 93\n",
      "Epoch: 160. Training_Loss: 0.11037875071633607.Testing_Loss:0.1541973754763603. Accuracy: 94\n",
      "Epoch: 162. Training_Loss: 0.11849481437820941.Testing_Loss:0.19170814752578735. Accuracy: 92\n",
      "Epoch: 164. Training_Loss: 0.11844212876167148.Testing_Loss:0.15749255418777466. Accuracy: 94\n",
      "Epoch: 166. Training_Loss: 0.13089388667140156.Testing_Loss:0.15013058185577394. Accuracy: 94\n",
      "Epoch: 168. Training_Loss: 0.1289383601397276.Testing_Loss:0.17609915733337403. Accuracy: 93\n",
      "Epoch: 170. Training_Loss: 0.11048413603566587.Testing_Loss:0.1696228563785553. Accuracy: 93\n",
      "Epoch: 172. Training_Loss: 0.10791080788476393.Testing_Loss:0.15523352473974228. Accuracy: 94\n",
      "Epoch: 174. Training_Loss: 0.14076405903324485.Testing_Loss:0.1809716284275055. Accuracy: 92\n",
      "Epoch: 176. Training_Loss: 0.1293950725812465.Testing_Loss:0.211515811085701. Accuracy: 91\n",
      "Epoch: 178. Training_Loss: 0.12319214292801917.Testing_Loss:0.14632610976696014. Accuracy: 94\n",
      "Epoch: 180. Training_Loss: 0.12533810210879892.Testing_Loss:0.1912878304719925. Accuracy: 92\n",
      "Epoch: 182. Training_Loss: 0.13582009298261255.Testing_Loss:0.18504148423671724. Accuracy: 92\n",
      "Epoch: 184. Training_Loss: 0.12938252952881157.Testing_Loss:0.15968151092529298. Accuracy: 94\n",
      "Epoch: 186. Training_Loss: 0.11726700922008604.Testing_Loss:0.15344620048999785. Accuracy: 94\n",
      "Epoch: 188. Training_Loss: 0.11276077840011567.Testing_Loss:0.2364485651254654. Accuracy: 92\n",
      "Epoch: 190. Training_Loss: 0.11453874205471948.Testing_Loss:0.2137073904275894. Accuracy: 93\n",
      "Epoch: 192. Training_Loss: 0.11490289401262999.Testing_Loss:0.16147963106632232. Accuracy: 94\n",
      "Epoch: 194. Training_Loss: 0.12373434531036764.Testing_Loss:0.16920218467712403. Accuracy: 93\n",
      "Epoch: 196. Training_Loss: 0.1369023669976741.Testing_Loss:0.2340184360742569. Accuracy: 92\n",
      "Epoch: 198. Training_Loss: 0.12296995520591736.Testing_Loss:0.1663008451461792. Accuracy: 93\n",
      "Epoch: 200. Training_Loss: 0.1132185438182205.Testing_Loss:0.21776567697525023. Accuracy: 92\n",
      "Epoch: 202. Training_Loss: 0.10381654795492068.Testing_Loss:0.22739967107772827. Accuracy: 92\n",
      "Epoch: 204. Training_Loss: 0.1185488459886983.Testing_Loss:0.15750563740730286. Accuracy: 94\n",
      "Epoch: 206. Training_Loss: 0.10727672919165343.Testing_Loss:0.17148310244083403. Accuracy: 94\n",
      "Epoch: 208. Training_Loss: 0.10236214043106884.Testing_Loss:0.12666898518800734. Accuracy: 95\n",
      "Epoch: 210. Training_Loss: 0.10026946861762553.Testing_Loss:0.11418475806713105. Accuracy: 95\n",
      "Epoch: 212. Training_Loss: 0.10902676009573042.Testing_Loss:0.15654683709144593. Accuracy: 93\n",
      "Epoch: 214. Training_Loss: 0.10508939466672018.Testing_Loss:0.12703445702791213. Accuracy: 95\n",
      "Epoch: 216. Training_Loss: 0.1012855737353675.Testing_Loss:0.12816197723150252. Accuracy: 95\n",
      "Epoch: 218. Training_Loss: 0.08979901997372508.Testing_Loss:0.12274843007326126. Accuracy: 95\n",
      "Epoch: 220. Training_Loss: 0.09590769797796384.Testing_Loss:0.15500924438238145. Accuracy: 94\n",
      "Epoch: 222. Training_Loss: 0.10950878279982135.Testing_Loss:0.15966587960720063. Accuracy: 94\n",
      "Epoch: 224. Training_Loss: 0.1072739761439152.Testing_Loss:0.161055126786232. Accuracy: 94\n",
      "Epoch: 226. Training_Loss: 0.1245192593196407.Testing_Loss:0.12399008125066757. Accuracy: 94\n",
      "Epoch: 228. Training_Loss: 0.12260240246541798.Testing_Loss:0.1674463778734207. Accuracy: 93\n",
      "Epoch: 230. Training_Loss: 0.10341433074790984.Testing_Loss:0.12265886068344116. Accuracy: 95\n",
      "Epoch: 232. Training_Loss: 0.11711261386517435.Testing_Loss:0.2705241501331329. Accuracy: 91\n",
      "Epoch: 234. Training_Loss: 0.12702826305758208.Testing_Loss:0.2106487661600113. Accuracy: 93\n",
      "Epoch: 236. Training_Loss: 0.13455927255563438.Testing_Loss:0.17385883033275604. Accuracy: 94\n",
      "Epoch: 238. Training_Loss: 0.12619588314555585.Testing_Loss:0.14533664286136627. Accuracy: 94\n",
      "Epoch: 240. Training_Loss: 0.12285724625689909.Testing_Loss:0.20082911849021912. Accuracy: 93\n",
      "Epoch: 242. Training_Loss: 0.11212138796690851.Testing_Loss:0.1369342103600502. Accuracy: 94\n",
      "Epoch: 244. Training_Loss: 0.13113492238335311.Testing_Loss:0.1426275283098221. Accuracy: 94\n",
      "Epoch: 246. Training_Loss: 0.1456354287220165.Testing_Loss:0.21503310799598693. Accuracy: 92\n",
      "Epoch: 248. Training_Loss: 0.12160015653353184.Testing_Loss:0.19986398220062257. Accuracy: 92\n",
      "Epoch: 250. Training_Loss: 0.15494785638293251.Testing_Loss:0.19448943585157394. Accuracy: 92\n",
      "Epoch: 252. Training_Loss: 0.13386853330302984.Testing_Loss:0.21276724934577942. Accuracy: 92\n",
      "Epoch: 254. Training_Loss: 0.11588340229354799.Testing_Loss:0.17000573575496675. Accuracy: 93\n",
      "Epoch: 256. Training_Loss: 0.14270172151736915.Testing_Loss:0.3125293582677841. Accuracy: 91\n",
      "Epoch: 258. Training_Loss: 0.11112701945239678.Testing_Loss:0.2597499221563339. Accuracy: 92\n",
      "Epoch: 260. Training_Loss: 0.11214839562308043.Testing_Loss:0.1502135157585144. Accuracy: 94\n",
      "Epoch: 262. Training_Loss: 0.1177964664530009.Testing_Loss:0.13273512572050095. Accuracy: 95\n",
      "Epoch: 264. Training_Loss: 0.09897621255367994.Testing_Loss:0.12618923634290696. Accuracy: 95\n",
      "Epoch: 266. Training_Loss: 0.08695858187275007.Testing_Loss:0.10500195175409317. Accuracy: 96\n",
      "Epoch: 268. Training_Loss: 0.07364062272245064.Testing_Loss:0.14889363646507264. Accuracy: 95\n",
      "Epoch: 270. Training_Loss: 0.08926560397958383.Testing_Loss:0.0988199070096016. Accuracy: 96\n",
      "Epoch: 272. Training_Loss: 0.0899614644004032.Testing_Loss:0.12160266488790512. Accuracy: 95\n",
      "Epoch: 274. Training_Loss: 0.10435992968268692.Testing_Loss:0.11671599894762039. Accuracy: 95\n",
      "Epoch: 276. Training_Loss: 0.08226341631961986.Testing_Loss:0.13489710986614228. Accuracy: 95\n",
      "Epoch: 278. Training_Loss: 0.08525946305599064.Testing_Loss:0.15106574445962906. Accuracy: 94\n",
      "Epoch: 280. Training_Loss: 0.07507012478890829.Testing_Loss:0.10580422729253769. Accuracy: 96\n",
      "Epoch: 282. Training_Loss: 0.10160629355232231.Testing_Loss:0.14339544773101806. Accuracy: 95\n",
      "Epoch: 284. Training_Loss: 0.09793609258485958.Testing_Loss:0.16150663793087006. Accuracy: 94\n",
      "Epoch: 286. Training_Loss: 0.12823660811409354.Testing_Loss:0.25167314410209657. Accuracy: 91\n",
      "Epoch: 288. Training_Loss: 0.10448783374158666.Testing_Loss:0.15773195922374725. Accuracy: 94\n",
      "Epoch: 290. Training_Loss: 0.11757947702426463.Testing_Loss:0.2427026629447937. Accuracy: 92\n",
      "Epoch: 292. Training_Loss: 0.11212079378310591.Testing_Loss:0.1730262666940689. Accuracy: 94\n",
      "Epoch: 294. Training_Loss: 0.12546582834329456.Testing_Loss:0.20849378854036332. Accuracy: 92\n",
      "Epoch: 296. Training_Loss: 0.09218950077774934.Testing_Loss:0.1367030292749405. Accuracy: 95\n",
      "Epoch: 298. Training_Loss: 0.08038133685477078.Testing_Loss:0.10844230204820633. Accuracy: 95\n",
      "Epoch: 300. Training_Loss: 0.0856722894241102.Testing_Loss:0.09203931391239166. Accuracy: 96\n",
      "Epoch: 302. Training_Loss: 0.08274968818295747.Testing_Loss:0.08425353914499283. Accuracy: 96\n",
      "Epoch: 304. Training_Loss: 0.096918250026647.Testing_Loss:0.17404095828533173. Accuracy: 94\n",
      "Epoch: 306. Training_Loss: 0.0733219074900262.Testing_Loss:0.09904672056436539. Accuracy: 96\n",
      "Epoch: 308. Training_Loss: 0.07927884464152157.Testing_Loss:0.08661424443125725. Accuracy: 96\n",
      "Epoch: 310. Training_Loss: 0.09106711036292836.Testing_Loss:0.10512665510177613. Accuracy: 96\n",
      "Epoch: 312. Training_Loss: 0.1029789792955853.Testing_Loss:0.10515334159135818. Accuracy: 96\n",
      "Epoch: 314. Training_Loss: 0.08856856951024383.Testing_Loss:0.12999814748764038. Accuracy: 95\n",
      "Epoch: 316. Training_Loss: 0.0848659371258691.Testing_Loss:0.09996959343552589. Accuracy: 96\n",
      "Epoch: 318. Training_Loss: 0.08342740102671087.Testing_Loss:0.12669560611248015. Accuracy: 95\n",
      "Epoch: 320. Training_Loss: 0.08022406249074265.Testing_Loss:0.11489528119564056. Accuracy: 96\n",
      "Epoch: 322. Training_Loss: 0.0841176641988568.Testing_Loss:0.10447996258735656. Accuracy: 96\n",
      "Epoch: 324. Training_Loss: 0.08492358349030837.Testing_Loss:0.1364872932434082. Accuracy: 95\n",
      "Epoch: 326. Training_Loss: 0.08395328716142103.Testing_Loss:0.11528054028749465. Accuracy: 95\n",
      "Epoch: 328. Training_Loss: 0.08398447473882698.Testing_Loss:0.11318747401237488. Accuracy: 95\n",
      "Epoch: 330. Training_Loss: 0.06446857695118524.Testing_Loss:0.11128375083208084. Accuracy: 96\n",
      "Epoch: 332. Training_Loss: 0.08064408204518259.Testing_Loss:0.08525632619857788. Accuracy: 96\n",
      "Epoch: 334. Training_Loss: 0.10374888696242124.Testing_Loss:0.08106770068407058. Accuracy: 96\n",
      "Epoch: 336. Training_Loss: 0.1102766896947287.Testing_Loss:0.11554606705904007. Accuracy: 95\n",
      "Epoch: 338. Training_Loss: 0.08335958328098059.Testing_Loss:0.17711775302886962. Accuracy: 94\n",
      "Epoch: 340. Training_Loss: 0.09786111931316555.Testing_Loss:0.17770059406757355. Accuracy: 94\n",
      "Epoch: 342. Training_Loss: 0.11217305215541273.Testing_Loss:0.14833539128303527. Accuracy: 94\n",
      "Epoch: 344. Training_Loss: 0.08764712722040713.Testing_Loss:0.12843980640172958. Accuracy: 95\n",
      "Epoch: 346. Training_Loss: 0.11344513343647122.Testing_Loss:0.1334435150027275. Accuracy: 94\n",
      "Epoch: 348. Training_Loss: 0.10363465180853382.Testing_Loss:0.25112087428569796. Accuracy: 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350. Training_Loss: 0.10020910116145387.Testing_Loss:0.12013991922140121. Accuracy: 95\n",
      "Epoch: 352. Training_Loss: 0.09256020066095516.Testing_Loss:0.1224119320511818. Accuracy: 95\n",
      "Epoch: 354. Training_Loss: 0.07933640119154006.Testing_Loss:0.17079244256019593. Accuracy: 94\n",
      "Epoch: 356. Training_Loss: 0.07414029765641317.Testing_Loss:0.08638014495372773. Accuracy: 96\n",
      "Epoch: 358. Training_Loss: 0.08123918081400916.Testing_Loss:0.0928384706377983. Accuracy: 96\n",
      "Epoch: 360. Training_Loss: 0.06561074763885699.Testing_Loss:0.11719637662172318. Accuracy: 95\n",
      "Epoch: 362. Training_Loss: 0.08201865447335877.Testing_Loss:0.08389768227934838. Accuracy: 96\n",
      "Epoch: 364. Training_Loss: 0.085279377293773.Testing_Loss:0.13081797063350678. Accuracy: 94\n",
      "Epoch: 366. Training_Loss: 0.10039367887657136.Testing_Loss:0.10463545769453049. Accuracy: 96\n",
      "Epoch: 368. Training_Loss: 0.09904495539376512.Testing_Loss:0.19530288279056549. Accuracy: 93\n",
      "Epoch: 370. Training_Loss: 0.08345085402834229.Testing_Loss:0.1438272088766098. Accuracy: 95\n",
      "Epoch: 372. Training_Loss: 0.0764687820628751.Testing_Loss:0.08078574985265732. Accuracy: 96\n",
      "Epoch: 374. Training_Loss: 0.0833260306972079.Testing_Loss:0.10079575777053833. Accuracy: 96\n",
      "Epoch: 376. Training_Loss: 0.08343386743217707.Testing_Loss:0.11971828937530518. Accuracy: 95\n",
      "Epoch: 378. Training_Loss: 0.07347876345738769.Testing_Loss:0.08020885214209557. Accuracy: 97\n",
      "Epoch: 380. Training_Loss: 0.07334020533016883.Testing_Loss:0.07905370220541955. Accuracy: 97\n",
      "Epoch: 382. Training_Loss: 0.08435209142044187.Testing_Loss:0.11580882966518402. Accuracy: 95\n",
      "Epoch: 384. Training_Loss: 0.08474768238374963.Testing_Loss:0.0928790420293808. Accuracy: 96\n",
      "Epoch: 386. Training_Loss: 0.0821790398331359.Testing_Loss:0.08070835173130035. Accuracy: 96\n",
      "Epoch: 388. Training_Loss: 0.07263954155496322.Testing_Loss:0.10235243290662766. Accuracy: 96\n",
      "Epoch: 390. Training_Loss: 0.06983971747104079.Testing_Loss:0.08430405855178832. Accuracy: 97\n",
      "Epoch: 392. Training_Loss: 0.08726848452351987.Testing_Loss:0.1304006978869438. Accuracy: 95\n",
      "Epoch: 394. Training_Loss: 0.10259254340780899.Testing_Loss:0.09000808224081994. Accuracy: 96\n",
      "Epoch: 396. Training_Loss: 0.09392154816305265.Testing_Loss:0.11355788111686707. Accuracy: 96\n",
      "Epoch: 398. Training_Loss: 0.07894857067731209.Testing_Loss:0.13754630982875823. Accuracy: 95\n",
      "Epoch: 400. Training_Loss: 0.10408139089122415.Testing_Loss:0.179605895280838. Accuracy: 94\n",
      "Epoch: 402. Training_Loss: 0.11144847792456858.Testing_Loss:0.2843442469835281. Accuracy: 92\n",
      "Epoch: 404. Training_Loss: 0.11323404376162216.Testing_Loss:0.17880524098873138. Accuracy: 94\n",
      "Epoch: 406. Training_Loss: 0.09900052438024431.Testing_Loss:0.1358805254101753. Accuracy: 94\n",
      "Epoch: 408. Training_Loss: 0.0883820676826872.Testing_Loss:0.10810454189777374. Accuracy: 96\n",
      "Epoch: 410. Training_Loss: 0.10422232351265848.Testing_Loss:0.11247340589761734. Accuracy: 96\n",
      "Epoch: 412. Training_Loss: 0.10043768340256065.Testing_Loss:0.11085837930440903. Accuracy: 95\n",
      "Epoch: 414. Training_Loss: 0.08688651118427515.Testing_Loss:0.1172207310795784. Accuracy: 96\n",
      "Epoch: 416. Training_Loss: 0.08969130317564122.Testing_Loss:0.0891158938407898. Accuracy: 96\n",
      "Epoch: 418. Training_Loss: 0.07342183971195482.Testing_Loss:0.06852664202451705. Accuracy: 97\n",
      "Epoch: 420. Training_Loss: 0.061829972750274464.Testing_Loss:0.06310060024261474. Accuracy: 97\n",
      "Epoch: 422. Training_Loss: 0.06441914834431373.Testing_Loss:0.06855280175805092. Accuracy: 97\n",
      "Epoch: 424. Training_Loss: 0.06285014684544876.Testing_Loss:0.08040973991155624. Accuracy: 96\n",
      "Epoch: 426. Training_Loss: 0.06793094868771732.Testing_Loss:0.09636760205030441. Accuracy: 96\n",
      "Epoch: 428. Training_Loss: 0.06309918471379206.Testing_Loss:0.07190141156315803. Accuracy: 97\n",
      "Epoch: 430. Training_Loss: 0.07644246373092756.Testing_Loss:0.0776730790734291. Accuracy: 97\n",
      "Epoch: 432. Training_Loss: 0.08965187310241163.Testing_Loss:0.11782025843858719. Accuracy: 95\n",
      "Epoch: 434. Training_Loss: 0.09279824447003193.Testing_Loss:0.21207726895809173. Accuracy: 92\n",
      "Epoch: 436. Training_Loss: 0.07624658063286915.Testing_Loss:0.21616587042808533. Accuracy: 94\n",
      "Epoch: 438. Training_Loss: 0.0753020781558007.Testing_Loss:0.07079988270998001. Accuracy: 97\n",
      "Epoch: 440. Training_Loss: 0.08134445361793041.Testing_Loss:0.097497096657753. Accuracy: 96\n",
      "Epoch: 442. Training_Loss: 0.07944662772933953.Testing_Loss:0.10454567074775696. Accuracy: 95\n",
      "Epoch: 444. Training_Loss: 0.0844230440852698.Testing_Loss:0.1743384450674057. Accuracy: 94\n",
      "Epoch: 446. Training_Loss: 0.07962095658876933.Testing_Loss:0.08894127160310746. Accuracy: 96\n",
      "Epoch: 448. Training_Loss: 0.08770630415529013.Testing_Loss:0.08234848603606224. Accuracy: 97\n",
      "Epoch: 450. Training_Loss: 0.07584111369214952.Testing_Loss:0.09888316243886948. Accuracy: 96\n",
      "Epoch: 452. Training_Loss: 0.0694538795214612.Testing_Loss:0.07690088152885437. Accuracy: 97\n",
      "Epoch: 454. Training_Loss: 0.06761208828538656.Testing_Loss:0.06343738511204719. Accuracy: 97\n",
      "Epoch: 456. Training_Loss: 0.06489267031429335.Testing_Loss:0.06831298172473907. Accuracy: 97\n",
      "Epoch: 458. Training_Loss: 0.06337378564057872.Testing_Loss:0.08663533627986908. Accuracy: 97\n",
      "Epoch: 460. Training_Loss: 0.06980458728503436.Testing_Loss:0.07130765244364738. Accuracy: 97\n",
      "Epoch: 462. Training_Loss: 0.07133957976475358.Testing_Loss:0.12357739061117172. Accuracy: 95\n",
      "Epoch: 464. Training_Loss: 0.06403289598529227.Testing_Loss:0.07272709012031556. Accuracy: 97\n",
      "Epoch: 466. Training_Loss: 0.05556910269660875.Testing_Loss:0.06476979181170464. Accuracy: 97\n",
      "Epoch: 468. Training_Loss: 0.06632223050110042.Testing_Loss:0.07382091730833054. Accuracy: 97\n",
      "Epoch: 470. Training_Loss: 0.06254348694346845.Testing_Loss:0.05630572661757469. Accuracy: 97\n",
      "Epoch: 472. Training_Loss: 0.08021271921461448.Testing_Loss:0.07512538805603981. Accuracy: 97\n",
      "Epoch: 474. Training_Loss: 0.06579665341996588.Testing_Loss:0.08064975887537003. Accuracy: 96\n",
      "Epoch: 476. Training_Loss: 0.0839540729066357.Testing_Loss:0.18955763578414916. Accuracy: 94\n",
      "Epoch: 478. Training_Loss: 0.07927800656761974.Testing_Loss:0.1052808478474617. Accuracy: 96\n",
      "Epoch: 480. Training_Loss: 0.08922058920143172.Testing_Loss:0.14082581847906112. Accuracy: 94\n",
      "Epoch: 482. Training_Loss: 0.07983081988641061.Testing_Loss:0.07872468829154969. Accuracy: 96\n",
      "Epoch: 484. Training_Loss: 0.0844115023210179.Testing_Loss:0.10644000768661499. Accuracy: 96\n",
      "Epoch: 486. Training_Loss: 0.10246644675498828.Testing_Loss:0.1002687469124794. Accuracy: 96\n",
      "Epoch: 488. Training_Loss: 0.09508331850520335.Testing_Loss:0.2076628774404526. Accuracy: 93\n",
      "Epoch: 490. Training_Loss: 0.07302722375607118.Testing_Loss:0.2228863924741745. Accuracy: 94\n",
      "Epoch: 492. Training_Loss: 0.07369556836783886.Testing_Loss:0.08253298997879029. Accuracy: 96\n",
      "Epoch: 494. Training_Loss: 0.05834723563748412.Testing_Loss:0.07677936628460884. Accuracy: 97\n",
      "Epoch: 496. Training_Loss: 0.0565158459066879.Testing_Loss:0.05991171151399612. Accuracy: 97\n",
      "Epoch: 498. Training_Loss: 0.06073090777499601.Testing_Loss:0.06774955540895462. Accuracy: 97\n",
      "Epoch: 500. Training_Loss: 0.0842684973613359.Testing_Loss:0.09594158977270126. Accuracy: 96\n",
      "Epoch: 502. Training_Loss: 0.06163488724268973.Testing_Loss:0.07956043779850006. Accuracy: 97\n",
      "Epoch: 504. Training_Loss: 0.06976252314052545.Testing_Loss:0.08884308487176895. Accuracy: 96\n",
      "Epoch: 506. Training_Loss: 0.07332018626038916.Testing_Loss:0.08725400418043136. Accuracy: 96\n",
      "Epoch: 508. Training_Loss: 0.07174815773032606.Testing_Loss:0.09998306930065155. Accuracy: 96\n",
      "Epoch: 510. Training_Loss: 0.074895036930684.Testing_Loss:0.08178566247224808. Accuracy: 97\n",
      "Epoch: 512. Training_Loss: 0.07385828084079549.Testing_Loss:0.06643502414226532. Accuracy: 97\n",
      "Epoch: 514. Training_Loss: 0.07242964638862759.Testing_Loss:0.06472701951861382. Accuracy: 97\n",
      "Epoch: 516. Training_Loss: 0.06491039897082373.Testing_Loss:0.06991818472743035. Accuracy: 97\n",
      "Epoch: 518. Training_Loss: 0.06113496967009269.Testing_Loss:0.15892251431941987. Accuracy: 95\n",
      "Epoch: 520. Training_Loss: 0.06628128662123345.Testing_Loss:0.062149501964449884. Accuracy: 97\n",
      "Epoch: 522. Training_Loss: 0.06685507777729072.Testing_Loss:0.05295213758945465. Accuracy: 97\n",
      "Epoch: 524. Training_Loss: 0.06519289081916213.Testing_Loss:0.07317595407366753. Accuracy: 97\n",
      "Epoch: 526. Training_Loss: 0.06888325029285625.Testing_Loss:0.17771590054035186. Accuracy: 94\n",
      "Epoch: 528. Training_Loss: 0.0859079175570514.Testing_Loss:0.13169509619474412. Accuracy: 95\n",
      "Epoch: 530. Training_Loss: 0.06928835425060242.Testing_Loss:0.13583823591470717. Accuracy: 96\n",
      "Epoch: 532. Training_Loss: 0.08718563575530425.Testing_Loss:0.19413850009441375. Accuracy: 94\n",
      "Epoch: 534. Training_Loss: 0.08157106197904795.Testing_Loss:0.20033778250217438. Accuracy: 93\n",
      "Epoch: 536. Training_Loss: 0.06929287032107823.Testing_Loss:0.10111279040575027. Accuracy: 96\n",
      "Epoch: 538. Training_Loss: 0.06099085007735994.Testing_Loss:0.0815806321799755. Accuracy: 96\n",
      "Epoch: 540. Training_Loss: 0.05883628854644485.Testing_Loss:0.11319638937711715. Accuracy: 96\n",
      "Epoch: 542. Training_Loss: 0.05344774438708555.Testing_Loss:0.06435960829257965. Accuracy: 98\n",
      "Epoch: 544. Training_Loss: 0.064875831711106.Testing_Loss:0.08989689201116562. Accuracy: 97\n",
      "Epoch: 546. Training_Loss: 0.06918627602863126.Testing_Loss:0.06741900593042374. Accuracy: 97\n",
      "Epoch: 548. Training_Loss: 0.07970889005810022.Testing_Loss:0.07238939553499221. Accuracy: 97\n",
      "Epoch: 550. Training_Loss: 0.06835630000568926.Testing_Loss:0.07171376645565034. Accuracy: 97\n",
      "Epoch: 552. Training_Loss: 0.06708522423286922.Testing_Loss:0.09971358925104142. Accuracy: 96\n",
      "Epoch: 554. Training_Loss: 0.05831180413952097.Testing_Loss:0.053163733705878256. Accuracy: 97\n",
      "Epoch: 556. Training_Loss: 0.054961564688710496.Testing_Loss:0.051600610837340355. Accuracy: 98\n",
      "Epoch: 558. Training_Loss: 0.06078457157127559.Testing_Loss:0.07583347111940383. Accuracy: 97\n",
      "Epoch: 560. Training_Loss: 0.06002882539178245.Testing_Loss:0.08224528580904007. Accuracy: 96\n",
      "Epoch: 562. Training_Loss: 0.07545641413889825.Testing_Loss:0.06870290413498878. Accuracy: 97\n",
      "Epoch: 564. Training_Loss: 0.0636962701973971.Testing_Loss:0.05655848160386086. Accuracy: 98\n",
      "Epoch: 566. Training_Loss: 0.05635214882204309.Testing_Loss:0.06591115295886993. Accuracy: 97\n",
      "Epoch: 568. Training_Loss: 0.0642247716896236.Testing_Loss:0.050097587332129476. Accuracy: 98\n",
      "Epoch: 570. Training_Loss: 0.07594373665051535.Testing_Loss:0.08855678215622902. Accuracy: 96\n",
      "Epoch: 572. Training_Loss: 0.06407323697931133.Testing_Loss:0.10443726480007172. Accuracy: 96\n",
      "Epoch: 574. Training_Loss: 0.07298129660193808.Testing_Loss:0.07270261347293853. Accuracy: 97\n",
      "Epoch: 576. Training_Loss: 0.08717727736802772.Testing_Loss:0.09426381886005401. Accuracy: 96\n",
      "Epoch: 578. Training_Loss: 0.07570851169293746.Testing_Loss:0.09352113157510758. Accuracy: 96\n",
      "Epoch: 580. Training_Loss: 0.07234074480948038.Testing_Loss:0.045890824124217036. Accuracy: 98\n",
      "Epoch: 582. Training_Loss: 0.06309154839254916.Testing_Loss:0.04981537461280823. Accuracy: 98\n",
      "Epoch: 584. Training_Loss: 0.0609456745442003.Testing_Loss:0.06947762072086335. Accuracy: 97\n",
      "Epoch: 586. Training_Loss: 0.07227838013204746.Testing_Loss:0.06040722206234932. Accuracy: 97\n",
      "Epoch: 588. Training_Loss: 0.0701307745766826.Testing_Loss:0.09184780120849609. Accuracy: 97\n",
      "Epoch: 590. Training_Loss: 0.06901473872130737.Testing_Loss:0.07827680259943008. Accuracy: 96\n",
      "Epoch: 592. Training_Loss: 0.051543007051805034.Testing_Loss:0.05035857483744621. Accuracy: 97\n",
      "Epoch: 594. Training_Loss: 0.057372183830011636.Testing_Loss:0.06279958412051201. Accuracy: 97\n",
      "Epoch: 596. Training_Loss: 0.07155116338981315.Testing_Loss:0.07708154693245887. Accuracy: 97\n",
      "Epoch: 598. Training_Loss: 0.0699252613412682.Testing_Loss:0.06367321759462356. Accuracy: 98\n",
      "Epoch: 600. Training_Loss: 0.06863611127482727.Testing_Loss:0.07833342030644416. Accuracy: 97\n",
      "Epoch: 602. Training_Loss: 0.07125640686717816.Testing_Loss:0.21499295234680177. Accuracy: 94\n",
      "Epoch: 604. Training_Loss: 0.07426249916898087.Testing_Loss:0.08382928892970085. Accuracy: 97\n",
      "Epoch: 606. Training_Loss: 0.054696015373338014.Testing_Loss:0.0881122186779976. Accuracy: 97\n",
      "Epoch: 608. Training_Loss: 0.07206271329778247.Testing_Loss:0.06255354583263398. Accuracy: 97\n",
      "Epoch: 610. Training_Loss: 0.07133225159486756.Testing_Loss:0.04954430535435676. Accuracy: 98\n",
      "Epoch: 612. Training_Loss: 0.06856987217906862.Testing_Loss:0.10794346630573273. Accuracy: 96\n",
      "Epoch: 614. Training_Loss: 0.07190957214334048.Testing_Loss:0.055887182056903836. Accuracy: 98\n",
      "Epoch: 616. Training_Loss: 0.05398260458605364.Testing_Loss:0.05688397064805031. Accuracy: 98\n",
      "Epoch: 618. Training_Loss: 0.07241041868110187.Testing_Loss:0.06090827882289886. Accuracy: 97\n",
      "Epoch: 620. Training_Loss: 0.059380579099524766.Testing_Loss:0.08683491572737694. Accuracy: 97\n",
      "Epoch: 622. Training_Loss: 0.05690910907287616.Testing_Loss:0.10286297202110291. Accuracy: 96\n",
      "Epoch: 624. Training_Loss: 0.05786855559563264.Testing_Loss:0.057107483968138695. Accuracy: 98\n",
      "Epoch: 626. Training_Loss: 0.06377782582421787.Testing_Loss:0.05344737470149994. Accuracy: 98\n",
      "Epoch: 628. Training_Loss: 0.05031182445236482.Testing_Loss:0.07116104811429977. Accuracy: 97\n",
      "Epoch: 630. Training_Loss: 0.04633158753858879.Testing_Loss:0.038867298513650894. Accuracy: 98\n",
      "Epoch: 632. Training_Loss: 0.06393914377258625.Testing_Loss:0.06446736678481102. Accuracy: 97\n",
      "Epoch: 634. Training_Loss: 0.0527796249371022.Testing_Loss:0.04563735388219357. Accuracy: 98\n",
      "Epoch: 636. Training_Loss: 0.05539596141898073.Testing_Loss:0.04902097396552563. Accuracy: 98\n",
      "Epoch: 638. Training_Loss: 0.05508746320265345.Testing_Loss:0.10653334856033325. Accuracy: 96\n",
      "Epoch: 640. Training_Loss: 0.06228023546282202.Testing_Loss:0.08538446426391602. Accuracy: 97\n",
      "Epoch: 642. Training_Loss: 0.06752964144106954.Testing_Loss:0.05052360445261002. Accuracy: 97\n",
      "Epoch: 644. Training_Loss: 0.06844801979605108.Testing_Loss:0.09754681140184403. Accuracy: 96\n",
      "Epoch: 646. Training_Loss: 0.09309472325548995.Testing_Loss:0.14852195531129836. Accuracy: 95\n",
      "Epoch: 648. Training_Loss: 0.07891005164128728.Testing_Loss:0.13414428383111954. Accuracy: 96\n",
      "Epoch: 650. Training_Loss: 0.09911976006696932.Testing_Loss:0.1702426165342331. Accuracy: 94\n",
      "Epoch: 652. Training_Loss: 0.07127618900267407.Testing_Loss:0.12838321030139924. Accuracy: 95\n",
      "Epoch: 654. Training_Loss: 0.0860611283860635.Testing_Loss:0.06140886023640633. Accuracy: 98\n",
      "Epoch: 656. Training_Loss: 0.10499132849508896.Testing_Loss:0.12281332910060883. Accuracy: 95\n",
      "Epoch: 658. Training_Loss: 0.09505936864297837.Testing_Loss:0.11432310044765473. Accuracy: 96\n",
      "Epoch: 660. Training_Loss: 0.11447055439930409.Testing_Loss:0.188048854470253. Accuracy: 93\n",
      "Epoch: 662. Training_Loss: 0.09261090942891315.Testing_Loss:0.11558214277029037. Accuracy: 96\n",
      "Epoch: 664. Training_Loss: 0.11645397206302732.Testing_Loss:0.07535186037421227. Accuracy: 97\n",
      "Epoch: 666. Training_Loss: 0.10804295598063618.Testing_Loss:0.14763458222150802. Accuracy: 95\n",
      "Epoch: 668. Training_Loss: 0.09380277915624902.Testing_Loss:0.11897852718830108. Accuracy: 96\n",
      "Epoch: 670. Training_Loss: 0.06420305772917345.Testing_Loss:0.10494691282510757. Accuracy: 96\n",
      "Epoch: 672. Training_Loss: 0.06531634050770663.Testing_Loss:0.08566680550575256. Accuracy: 96\n",
      "Epoch: 674. Training_Loss: 0.06392539406078868.Testing_Loss:0.05965917706489563. Accuracy: 98\n",
      "Epoch: 676. Training_Loss: 0.06112229858990759.Testing_Loss:0.10129644498229026. Accuracy: 96\n",
      "Epoch: 678. Training_Loss: 0.05720624706009403.Testing_Loss:0.09701766669750214. Accuracy: 96\n",
      "Epoch: 680. Training_Loss: 0.05215130833676085.Testing_Loss:0.048746537417173386. Accuracy: 98\n",
      "Epoch: 682. Training_Loss: 0.061841057817218825.Testing_Loss:0.06003394350409508. Accuracy: 98\n",
      "Epoch: 684. Training_Loss: 0.0610675629141042.Testing_Loss:0.09283334314823151. Accuracy: 97\n",
      "Epoch: 686. Training_Loss: 0.08041137119289488.Testing_Loss:0.09755064845085144. Accuracy: 96\n",
      "Epoch: 688. Training_Loss: 0.07825738040264696.Testing_Loss:0.07034973278641701. Accuracy: 97\n",
      "Epoch: 690. Training_Loss: 0.05410920828580856.Testing_Loss:0.05983074456453323. Accuracy: 97\n",
      "Epoch: 692. Training_Loss: 0.05577526267734356.Testing_Loss:0.04543266594409943. Accuracy: 98\n",
      "Epoch: 694. Training_Loss: 0.05276767126633786.Testing_Loss:0.05307120978832245. Accuracy: 97\n",
      "Epoch: 696. Training_Loss: 0.053948111657518893.Testing_Loss:0.062160083651542665. Accuracy: 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 698. Training_Loss: 0.056390134850516915.Testing_Loss:0.07820653617382049. Accuracy: 97\n",
      "Epoch: 700. Training_Loss: 0.04489869212557096.Testing_Loss:0.04053107351064682. Accuracy: 98\n",
      "Epoch: 702. Training_Loss: 0.044378623671946116.Testing_Loss:0.05279798731207848. Accuracy: 98\n",
      "Epoch: 704. Training_Loss: 0.05808200829778798.Testing_Loss:0.06864981725811958. Accuracy: 97\n",
      "Epoch: 706. Training_Loss: 0.06090794628835283.Testing_Loss:0.03282464407384396. Accuracy: 98\n",
      "Epoch: 708. Training_Loss: 0.06422174494946375.Testing_Loss:0.0491185799241066. Accuracy: 98\n",
      "Epoch: 710. Training_Loss: 0.062127521116053686.Testing_Loss:0.06243229061365128. Accuracy: 97\n",
      "Epoch: 712. Training_Loss: 0.05722687183879316.Testing_Loss:0.07479640990495681. Accuracy: 97\n",
      "Epoch: 714. Training_Loss: 0.044224382771062665.Testing_Loss:0.03943721614778042. Accuracy: 98\n",
      "Epoch: 716. Training_Loss: 0.047074524336494505.Testing_Loss:0.07759052515029907. Accuracy: 97\n",
      "Epoch: 718. Training_Loss: 0.052982556269853376.Testing_Loss:0.05051461160182953. Accuracy: 98\n",
      "Epoch: 720. Training_Loss: 0.047720987000502646.Testing_Loss:0.05165468081831932. Accuracy: 98\n",
      "Epoch: 722. Training_Loss: 0.0671386168396566.Testing_Loss:0.06212309673428536. Accuracy: 97\n",
      "Epoch: 724. Training_Loss: 0.04391440941253677.Testing_Loss:0.04899518266320228. Accuracy: 98\n",
      "Epoch: 726. Training_Loss: 0.041532069924869575.Testing_Loss:0.05451989322900772. Accuracy: 98\n",
      "Epoch: 728. Training_Loss: 0.05513929978769738.Testing_Loss:0.0923290342092514. Accuracy: 96\n",
      "Epoch: 730. Training_Loss: 0.05803417318384163.Testing_Loss:0.08571802154183387. Accuracy: 96\n",
      "Epoch: 732. Training_Loss: 0.056312186672585085.Testing_Loss:0.0621374785900116. Accuracy: 98\n",
      "Epoch: 734. Training_Loss: 0.05189044261351228.Testing_Loss:0.045185650885105136. Accuracy: 98\n",
      "Epoch: 736. Training_Loss: 0.046011368453036994.Testing_Loss:0.060876183211803436. Accuracy: 97\n",
      "Epoch: 738. Training_Loss: 0.05294082571344916.Testing_Loss:0.034189865738153455. Accuracy: 98\n",
      "Epoch: 740. Training_Loss: 0.052080971145187505.Testing_Loss:0.04745400883257389. Accuracy: 98\n",
      "Epoch: 742. Training_Loss: 0.05187286523869261.Testing_Loss:0.05858616530895233. Accuracy: 98\n",
      "Epoch: 744. Training_Loss: 0.05221167523995973.Testing_Loss:0.04243954755365849. Accuracy: 98\n",
      "Epoch: 746. Training_Loss: 0.0637028715282213.Testing_Loss:0.05286132171750069. Accuracy: 98\n",
      "Epoch: 748. Training_Loss: 0.07275123262661509.Testing_Loss:0.10202423334121705. Accuracy: 96\n",
      "Epoch: 750. Training_Loss: 0.06613764015492052.Testing_Loss:0.08689995631575584. Accuracy: 97\n",
      "Epoch: 752. Training_Loss: 0.06785272754495963.Testing_Loss:0.06291159093379975. Accuracy: 97\n",
      "Epoch: 754. Training_Loss: 0.06314525968628004.Testing_Loss:0.057799500226974485. Accuracy: 97\n",
      "Epoch: 756. Training_Loss: 0.0706785149523057.Testing_Loss:0.040283435583114625. Accuracy: 98\n",
      "Epoch: 758. Training_Loss: 0.08920250332448632.Testing_Loss:0.0704059436917305. Accuracy: 97\n",
      "Epoch: 760. Training_Loss: 0.07748996349982917.Testing_Loss:0.12625212073326111. Accuracy: 96\n",
      "Epoch: 762. Training_Loss: 0.07534338138066232.Testing_Loss:0.1075433686375618. Accuracy: 96\n",
      "Epoch: 764. Training_Loss: 0.07783245839527808.Testing_Loss:0.06895563155412673. Accuracy: 97\n",
      "Epoch: 766. Training_Loss: 0.059891254524700344.Testing_Loss:0.04627324119210243. Accuracy: 98\n",
      "Epoch: 768. Training_Loss: 0.047343396639917046.Testing_Loss:0.05273272879421711. Accuracy: 98\n",
      "Epoch: 770. Training_Loss: 0.04922215855913237.Testing_Loss:0.06619945988059044. Accuracy: 98\n",
      "Epoch: 772. Training_Loss: 0.06729841051856056.Testing_Loss:0.05478413626551628. Accuracy: 97\n",
      "Epoch: 774. Training_Loss: 0.0563857656379696.Testing_Loss:0.050856472551822664. Accuracy: 98\n",
      "Epoch: 776. Training_Loss: 0.0578318644547835.Testing_Loss:0.08667142689228058. Accuracy: 97\n",
      "Epoch: 778. Training_Loss: 0.056445715366862714.Testing_Loss:0.042924045398831365. Accuracy: 98\n",
      "Epoch: 780. Training_Loss: 0.05724097516213078.Testing_Loss:0.04516720324754715. Accuracy: 98\n",
      "Epoch: 782. Training_Loss: 0.052844405989162624.Testing_Loss:0.049429457262158395. Accuracy: 98\n",
      "Epoch: 784. Training_Loss: 0.05964136784314178.Testing_Loss:0.07244062572717666. Accuracy: 97\n",
      "Epoch: 786. Training_Loss: 0.05536106583895162.Testing_Loss:0.0508121233433485. Accuracy: 98\n",
      "Epoch: 788. Training_Loss: 0.07355056039523333.Testing_Loss:0.0721055269241333. Accuracy: 97\n",
      "Epoch: 790. Training_Loss: 0.05192424371489324.Testing_Loss:0.1302285760641098. Accuracy: 96\n",
      "Epoch: 792. Training_Loss: 0.05297895512194373.Testing_Loss:0.07402367070317269. Accuracy: 97\n",
      "Epoch: 794. Training_Loss: 0.07509359871619381.Testing_Loss:0.04868917018175125. Accuracy: 98\n",
      "Epoch: 796. Training_Loss: 0.07437205253518187.Testing_Loss:0.05744762197136879. Accuracy: 97\n",
      "Epoch: 798. Training_Loss: 0.06918383503216319.Testing_Loss:0.06970965266227722. Accuracy: 97\n",
      "Epoch: 800. Training_Loss: 0.06532573164440691.Testing_Loss:0.0727850116789341. Accuracy: 97\n",
      "Epoch: 802. Training_Loss: 0.05747939721914008.Testing_Loss:0.05256828740239143. Accuracy: 98\n",
      "Epoch: 804. Training_Loss: 0.05143224913626909.Testing_Loss:0.04980112686753273. Accuracy: 98\n",
      "Epoch: 806. Training_Loss: 0.0432422645681072.Testing_Loss:0.05182439163327217. Accuracy: 97\n",
      "Epoch: 808. Training_Loss: 0.0565108961018268.Testing_Loss:0.05972009375691414. Accuracy: 97\n",
      "Epoch: 810. Training_Loss: 0.04275037517072633.Testing_Loss:0.05065404400229454. Accuracy: 98\n",
      "Epoch: 812. Training_Loss: 0.04626225402171258.Testing_Loss:0.0485428661108017. Accuracy: 98\n",
      "Epoch: 814. Training_Loss: 0.06378830561880022.Testing_Loss:0.1216265007853508. Accuracy: 96\n",
      "Epoch: 816. Training_Loss: 0.05551661396748386.Testing_Loss:0.1270524337887764. Accuracy: 95\n",
      "Epoch: 818. Training_Loss: 0.055459436698583886.Testing_Loss:0.04901013001799583. Accuracy: 98\n",
      "Epoch: 820. Training_Loss: 0.04894291020173114.Testing_Loss:0.044693656265735626. Accuracy: 98\n",
      "Epoch: 822. Training_Loss: 0.07110340500366874.Testing_Loss:0.09517601355910302. Accuracy: 96\n",
      "Epoch: 824. Training_Loss: 0.05428924347506836.Testing_Loss:0.06110978052020073. Accuracy: 97\n",
      "Epoch: 826. Training_Loss: 0.053298510232707486.Testing_Loss:0.07414497956633567. Accuracy: 97\n",
      "Epoch: 828. Training_Loss: 0.04614944777858909.Testing_Loss:0.09259863421320916. Accuracy: 97\n",
      "Epoch: 830. Training_Loss: 0.05311130007612519.Testing_Loss:0.044376126304268834. Accuracy: 98\n",
      "Epoch: 832. Training_Loss: 0.049740125599782914.Testing_Loss:0.040948597341775896. Accuracy: 98\n",
      "Epoch: 834. Training_Loss: 0.043664730415912345.Testing_Loss:0.0391229122877121. Accuracy: 98\n",
      "Epoch: 836. Training_Loss: 0.052452502175583504.Testing_Loss:0.05827909708023071. Accuracy: 97\n",
      "Epoch: 838. Training_Loss: 0.05013038337347098.Testing_Loss:0.04136535078287125. Accuracy: 98\n",
      "Epoch: 840. Training_Loss: 0.048842399613931775.Testing_Loss:0.052222474664449695. Accuracy: 98\n",
      "Epoch: 842. Training_Loss: 0.04329491984390188.Testing_Loss:0.06113962307572365. Accuracy: 97\n",
      "Epoch: 844. Training_Loss: 0.05198894770001061.Testing_Loss:0.10660847127437592. Accuracy: 96\n",
      "Epoch: 846. Training_Loss: 0.0581787853006972.Testing_Loss:0.0470950298011303. Accuracy: 98\n",
      "Epoch: 848. Training_Loss: 0.04815724446962122.Testing_Loss:0.07390637919306756. Accuracy: 97\n",
      "Epoch: 850. Training_Loss: 0.03956195984210353.Testing_Loss:0.03505545444786549. Accuracy: 98\n",
      "Epoch: 852. Training_Loss: 0.044168846419779584.Testing_Loss:0.06311697065830231. Accuracy: 97\n",
      "Epoch: 854. Training_Loss: 0.055949395609786734.Testing_Loss:0.05725378915667534. Accuracy: 97\n",
      "Epoch: 856. Training_Loss: 0.05964424554258585.Testing_Loss:0.10265077501535416. Accuracy: 96\n",
      "Epoch: 858. Training_Loss: 0.061880814289906994.Testing_Loss:0.08270977810025215. Accuracy: 97\n",
      "Epoch: 860. Training_Loss: 0.06553475870168768.Testing_Loss:0.04439102411270142. Accuracy: 98\n",
      "Epoch: 862. Training_Loss: 0.05948171959607862.Testing_Loss:0.048549240082502367. Accuracy: 98\n",
      "Epoch: 864. Training_Loss: 0.053185129625489935.Testing_Loss:0.04737565480172634. Accuracy: 98\n",
      "Epoch: 866. Training_Loss: 0.05055548978270963.Testing_Loss:0.03638275749981403. Accuracy: 98\n",
      "Epoch: 868. Training_Loss: 0.04918154040933587.Testing_Loss:0.0551999419927597. Accuracy: 98\n",
      "Epoch: 870. Training_Loss: 0.05945220866124146.Testing_Loss:0.04420952014625072. Accuracy: 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 872. Training_Loss: 0.05080971500137821.Testing_Loss:0.07798095718026161. Accuracy: 97\n",
      "Epoch: 874. Training_Loss: 0.057261342444689944.Testing_Loss:0.0513968039304018. Accuracy: 97\n",
      "Epoch: 876. Training_Loss: 0.05232733392040245.Testing_Loss:0.044639083370566365. Accuracy: 98\n",
      "Epoch: 878. Training_Loss: 0.0643799155659508.Testing_Loss:0.0829790249466896. Accuracy: 97\n",
      "Epoch: 880. Training_Loss: 0.06627903107437305.Testing_Loss:0.13537254929542542. Accuracy: 96\n",
      "Epoch: 882. Training_Loss: 0.08096447281423025.Testing_Loss:0.08651322722434998. Accuracy: 97\n",
      "Epoch: 884. Training_Loss: 0.07052337616914883.Testing_Loss:0.06009241789579391. Accuracy: 97\n",
      "Epoch: 886. Training_Loss: 0.06448745861416683.Testing_Loss:0.046815719828009604. Accuracy: 98\n",
      "Epoch: 888. Training_Loss: 0.08264955342747271.Testing_Loss:0.08233514577150344. Accuracy: 96\n",
      "Epoch: 890. Training_Loss: 0.07684090718976222.Testing_Loss:0.1291049227118492. Accuracy: 96\n",
      "Epoch: 892. Training_Loss: 0.07168211998214247.Testing_Loss:0.0569025807082653. Accuracy: 98\n",
      "Epoch: 894. Training_Loss: 0.053811210935236886.Testing_Loss:0.07704891711473465. Accuracy: 97\n",
      "Epoch: 896. Training_Loss: 0.052030653750989586.Testing_Loss:0.05423782467842102. Accuracy: 98\n",
      "Epoch: 898. Training_Loss: 0.04620182767393999.Testing_Loss:0.08463540077209472. Accuracy: 97\n",
      "Epoch: 900. Training_Loss: 0.04932953976094723.Testing_Loss:0.03937612883746624. Accuracy: 98\n",
      "Epoch: 902. Training_Loss: 0.053900505357887596.Testing_Loss:0.05539108067750931. Accuracy: 97\n",
      "Epoch: 904. Training_Loss: 0.05280351376859471.Testing_Loss:0.07883266881108283. Accuracy: 97\n",
      "Epoch: 906. Training_Loss: 0.07862989552086219.Testing_Loss:0.10804426521062852. Accuracy: 95\n",
      "Epoch: 908. Training_Loss: 0.05640136409783736.Testing_Loss:0.0723108172416687. Accuracy: 97\n",
      "Epoch: 910. Training_Loss: 0.0719571701483801.Testing_Loss:0.22252555191516876. Accuracy: 94\n",
      "Epoch: 912. Training_Loss: 0.06648570092511363.Testing_Loss:0.08386422842741012. Accuracy: 97\n",
      "Epoch: 914. Training_Loss: 0.05288755032233894.Testing_Loss:0.039895232766866684. Accuracy: 98\n",
      "Epoch: 916. Training_Loss: 0.05190041204332374.Testing_Loss:0.041205788403749465. Accuracy: 98\n",
      "Epoch: 918. Training_Loss: 0.057343766471603885.Testing_Loss:0.04508410543203354. Accuracy: 98\n",
      "Epoch: 920. Training_Loss: 0.045158833905588835.Testing_Loss:0.03919342383742332. Accuracy: 98\n",
      "Epoch: 922. Training_Loss: 0.06786350440233946.Testing_Loss:0.04482953697443008. Accuracy: 98\n",
      "Epoch: 924. Training_Loss: 0.05573011786327697.Testing_Loss:0.0657092772424221. Accuracy: 97\n",
      "Epoch: 926. Training_Loss: 0.04529166436986998.Testing_Loss:0.04622994214296341. Accuracy: 98\n",
      "Epoch: 928. Training_Loss: 0.04419351463729981.Testing_Loss:0.036651359498500825. Accuracy: 98\n",
      "Epoch: 930. Training_Loss: 0.05549012907431461.Testing_Loss:0.07114136219024658. Accuracy: 96\n",
      "Epoch: 932. Training_Loss: 0.06208778193104081.Testing_Loss:0.1078140176832676. Accuracy: 96\n",
      "Epoch: 934. Training_Loss: 0.06789914629189298.Testing_Loss:0.1153590589761734. Accuracy: 96\n",
      "Epoch: 936. Training_Loss: 0.057749240222619846.Testing_Loss:0.04161940924823284. Accuracy: 98\n",
      "Epoch: 938. Training_Loss: 0.049013617739547044.Testing_Loss:0.052321795374155045. Accuracy: 98\n",
      "Epoch: 940. Training_Loss: 0.05115355129237287.Testing_Loss:0.041224969550967216. Accuracy: 98\n",
      "Epoch: 942. Training_Loss: 0.04432950433692895.Testing_Loss:0.056733135133981705. Accuracy: 98\n",
      "Epoch: 944. Training_Loss: 0.06646518755587749.Testing_Loss:0.05270500108599663. Accuracy: 97\n",
      "Epoch: 946. Training_Loss: 0.05253317189635709.Testing_Loss:0.060407344996929166. Accuracy: 97\n",
      "Epoch: 948. Training_Loss: 0.05497548638959415.Testing_Loss:0.05530290529131889. Accuracy: 98\n",
      "Epoch: 950. Training_Loss: 0.06549291053670458.Testing_Loss:0.06762411445379257. Accuracy: 97\n",
      "Epoch: 952. Training_Loss: 0.06504902157757897.Testing_Loss:0.057094433903694154. Accuracy: 98\n",
      "Epoch: 954. Training_Loss: 0.08285736956167966.Testing_Loss:0.06327470317482949. Accuracy: 97\n",
      "Epoch: 956. Training_Loss: 0.06562768033472821.Testing_Loss:0.04643457680940628. Accuracy: 98\n",
      "Epoch: 958. Training_Loss: 0.07001018719165586.Testing_Loss:0.055128070339560506. Accuracy: 98\n",
      "Epoch: 960. Training_Loss: 0.06842977047199383.Testing_Loss:0.04536527022719383. Accuracy: 98\n",
      "Epoch: 962. Training_Loss: 0.07310464585316367.Testing_Loss:0.07250822111964225. Accuracy: 97\n",
      "Epoch: 964. Training_Loss: 0.0584444998530671.Testing_Loss:0.06469568461179734. Accuracy: 97\n",
      "Epoch: 966. Training_Loss: 0.05045420388341881.Testing_Loss:0.039197216555476186. Accuracy: 98\n",
      "Epoch: 968. Training_Loss: 0.0460952692956198.Testing_Loss:0.058838599175214765. Accuracy: 98\n",
      "Epoch: 970. Training_Loss: 0.043982860195683315.Testing_Loss:0.03539412282407284. Accuracy: 98\n",
      "Epoch: 972. Training_Loss: 0.050216409494169056.Testing_Loss:0.035762729868292806. Accuracy: 98\n",
      "Epoch: 974. Training_Loss: 0.0432607276015915.Testing_Loss:0.036709579452872274. Accuracy: 98\n",
      "Epoch: 976. Training_Loss: 0.03622168998117559.Testing_Loss:0.027149357367306948. Accuracy: 98\n",
      "Epoch: 978. Training_Loss: 0.04270579418516718.Testing_Loss:0.04409899860620499. Accuracy: 98\n",
      "Epoch: 980. Training_Loss: 0.04216375465330202.Testing_Loss:0.05135896056890488. Accuracy: 97\n",
      "Epoch: 982. Training_Loss: 0.03851222406956367.Testing_Loss:0.037708787992596624. Accuracy: 98\n",
      "Epoch: 984. Training_Loss: 0.05493685157853179.Testing_Loss:0.04899297654628754. Accuracy: 98\n",
      "Epoch: 986. Training_Loss: 0.05069755302974954.Testing_Loss:0.026756776683032512. Accuracy: 98\n",
      "Epoch: 988. Training_Loss: 0.0678134300687816.Testing_Loss:0.1644362837076187. Accuracy: 96\n",
      "Epoch: 990. Training_Loss: 0.07649487428716384.Testing_Loss:0.09300114512443543. Accuracy: 96\n",
      "Epoch: 992. Training_Loss: 0.06087891207425855.Testing_Loss:0.04108739942312241. Accuracy: 98\n",
      "Epoch: 994. Training_Loss: 0.08191101424745284.Testing_Loss:0.059010956436395645. Accuracy: 97\n",
      "Epoch: 996. Training_Loss: 0.08625567056878936.Testing_Loss:0.09377837181091309. Accuracy: 97\n",
      "Epoch: 998. Training_Loss: 0.07003310270374641.Testing_Loss:0.10734115540981293. Accuracy: 96\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    training_loss_list = []\n",
    "    testing_loss_list = []\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as tensors with gradient accumulation abilities\n",
    "        images = images.requires_grad_().cuda(1)\n",
    "        labels =labels.cuda(1)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        training_loss_list.append(loss.item())\n",
    "    for i, (images, labels) in enumerate(augment_loader):\n",
    "    # Load images as tensors with gradient accumulation abilities\n",
    "        images = images.requires_grad_().cuda(1)\n",
    "        labels =labels.cuda(1)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        training_loss_list.append(loss.item())\n",
    "    training_loss = sum(training_loss_list)/len(training_loss_list)    \n",
    "\n",
    "    model.eval()    \n",
    "    if(epoch%2==0):\n",
    "            # Calculate Accuracy         \n",
    "        correct = 0\n",
    "        total = 0\n",
    "            # Iterate through test dataset\n",
    "        losses = []\n",
    "        for images, labels in validation_loader:\n",
    "            # Load images to tensors with gradient accumulation abilities\n",
    "            images = images.requires_grad_().cuda(1)\n",
    "            labels = labels.cuda(1)\n",
    "\n",
    "            # Forward pass only to get logits/output\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            testing_loss_list.append(loss.item())\n",
    "            # Get predictions from the maximum value\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Total correct predictions\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "        test_loss = sum(testing_loss_list)/len(testing_loss_list)\n",
    "        torch.save(model.state_dict(),str(epoch)+'.pt')\n",
    "        print('Epoch: {}. Training_Loss: {}.Testing_Loss:{}. Accuracy: {}'.format(epoch, training_loss,test_loss ,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adarsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "tensor([0, 0, 0,  ..., 3, 3, 3], device='cuda:1')\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adarsh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_state_dict(torch.load('550'))\n",
    "with open('test_image.pkl', 'rb') as f:\n",
    "    X = np.array(pickle.load(f),dtype=np.float32)\n",
    "\n",
    "X= X.reshape(-1,1,28,28)    \n",
    "test_loader=torch.utils.data.DataLoader(X, batch_size=2000)  \n",
    "for images in test_loader:\n",
    "    images = images.requires_grad_().cuda(1)\n",
    "    y = F.softmax(model(images))\n",
    "    print(y.shape[0])\n",
    "    _, predicted = torch.max(y.data, 1)\n",
    "print(predicted)\n",
    "print(len(predicted))\n",
    "# access Variable's tensor, copy back to CPU, convert to numpy\n",
    "arr = predicted.data.cpu().numpy()\n",
    "arr=np.array(arr,dtype='uint8')\n",
    "final=train_dataset.get_class_labels(arr)\n",
    "print(len(final))\n",
    "# write CSV\n",
    "np.savetxt('ragja_palakkadavath434.csv', final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
