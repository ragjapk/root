{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:04.547612Z",
     "start_time": "2019-04-10T15:31:23.517647Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchsample as ts\n",
    "from torchsample.transforms import RandomRotate\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET\n",
    "Class for loading data set from the pickle format.\n",
    "\n",
    "Label encoding was performed as classes given were 2,3,0 and 6.\n",
    "\n",
    "Data augmentation was applied via few torch vision transformations on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:09.206463Z",
     "start_time": "2019-04-10T15:32:09.181447Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_files,transform):\n",
    "        super().__init__()\n",
    "        self.csv_files=csv_files\n",
    "        with open(csv_files[0], 'rb') as f:\n",
    "            X = np.array(pickle.load(f),dtype=np.float32)\n",
    "        \n",
    "        if csv_files[1] is not None:\n",
    "            with open(csv_files[1], 'rb') as g:\n",
    "                y = np.array(pickle.load(g))\n",
    "            le=LabelEncoder()\n",
    "            y_label=le.fit_transform(y)\n",
    "            self.y=y_label\n",
    "            self.le =le \n",
    "            \n",
    "        self.transform=transform\n",
    "        \n",
    "        self.X= X.reshape(-1,1,28,28)\n",
    "#         self.X= X.reshape(-1,1,28,28)\n",
    "#         print(np.mean(np.mean(self.X,axis=0)))\n",
    "              \n",
    "                \n",
    "    def get_class_count(self):\n",
    "        return len(self.le.classes_)\n",
    "    \n",
    "    def get_input_dim(self):\n",
    "        return self.X.shape[1]\n",
    "    \n",
    "    def get_class_labels(self,y_label):\n",
    "        le=self.le\n",
    "        return le.inverse_transform(y_label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "         z=self.X[idx]\n",
    "         #print(z.shape)\n",
    "         z=np.reshape(z, (28,28))\n",
    "         img_name = Image.fromarray(z)\n",
    "#         plt.imshow(img_name)\n",
    "         sample=self.X[idx]\n",
    "        \n",
    "         if self.transform is not None:\n",
    "            sample = self.transform(img_name)\n",
    "#             #plt.show()\n",
    "            sample= sample.reshape(1,28,28)         \n",
    "            return sample,self.y[idx]\n",
    "         \n",
    "         return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-Processing\n",
    "\n",
    "Data Augmentation was performed using the following torch vision transforms:\n",
    "\n",
    "(1) RandomHorizontalFlip\n",
    "\n",
    "(2) RandomAffine of degree 30 \n",
    "\n",
    "(3) Normalization of the pixel values of the images.\n",
    "\n",
    "Data was loaded as training, validation and augment sets with normalization performed for training data and transforms performed for augment data and normalization performed for validation data.\n",
    "\n",
    "Use of SubsetRandomSampler to split into train and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:12.243719Z",
     "start_time": "2019-04-10T15:32:11.516401Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_size=0.3\n",
    "shuffle=True\n",
    "valid_transform = transforms.Compose([transforms.ToTensor(),  transforms.Normalize(mean=[82.34472], std=[255]),])\n",
    "\n",
    "augment_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomAffine(30), transforms.ToTensor(),  transforms.Normalize(mean=[82.34472], std=[255]),])\n",
    "train_transform = transforms.Compose([ transforms.ToTensor(),  transforms.Normalize(mean=[82.34472], std=[255]),])\n",
    "\n",
    "train_dataset = ImageDataset(['train_image.pkl','train_label.pkl'],train_transform)\n",
    "valid_dataset = ImageDataset(['train_image.pkl','train_label.pkl'],valid_transform)\n",
    "augment_dataset = ImageDataset(['train_image.pkl','train_label.pkl'],augment_transform)\n",
    "#test_dataset = ImageDataset(['test_image.pkl', None],transforms.ToTensor())\n",
    "batch_size=512\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "if shuffle:\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "augment_loader = torch.utils.data.DataLoader(augment_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:14.348422Z",
     "start_time": "2019-04-10T15:32:14.345419Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Convolutional Neural Network\n",
    "CNN Network of 2 Convolution Layers followed by two fully connected layers and a layer of dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:17.414417Z",
     "start_time": "2019-04-10T15:32:17.389400Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batch1=nn.BatchNorm2d(32)\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batch2=nn.BatchNorm2d(64)\n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "#         self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.batch3=nn.BatchNorm2d(64)\n",
    "#         # Max pool 3\n",
    "#         self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64 * 4 * 4, out_features=60)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.outer = nn.Linear(in_features=60, out_features=4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Convolution 1\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.batch1(out)\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Convolution 2 \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.batch2(out)\n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "#         # Convolution 3 \n",
    "#         out = self.conv3(out)\n",
    "#         out = self.relu3(out)\n",
    "#         out = self.batch3(out)\n",
    "#         # Max pool 3 \n",
    "#         out = self.maxpool3(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        #out = self.fc2(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.outer(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer was used as learning algorithm and Cross Entropy was used as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T15:32:19.957428Z",
     "start_time": "2019-04-10T15:32:19.933399Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Network().cuda(1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-10T10:02:26.522Z"
    }
   },
   "outputs": [],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    training_loss_list = []\n",
    "    testing_loss_list = []\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as tensors with gradient accumulation abilities\n",
    "        images = images.requires_grad_().cuda(1)\n",
    "        labels =labels.cuda(1)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        training_loss_list.append(loss.item())\n",
    "    for i, (images, labels) in enumerate(augment_loader):\n",
    "    # Load images as tensors with gradient accumulation abilities\n",
    "        images = images.requires_grad_().cuda(1)\n",
    "        labels =labels.cuda(1)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        training_loss_list.append(loss.item())\n",
    "    training_loss = sum(training_loss_list)/len(training_loss_list)    \n",
    "\n",
    "    model.eval()    \n",
    "    if(epoch%2==0):\n",
    "            # Calculate Accuracy         \n",
    "        correct = 0\n",
    "        total = 0\n",
    "            # Iterate through test dataset\n",
    "        losses = []\n",
    "        for images, labels in validation_loader:\n",
    "            # Load images to tensors with gradient accumulation abilities\n",
    "            images = images.requires_grad_().cuda(1)\n",
    "            labels = labels.cuda(1)\n",
    "\n",
    "            # Forward pass only to get logits/output\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            testing_loss_list.append(loss.item())\n",
    "            # Get predictions from the maximum value\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Total correct predictions\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "        test_loss = sum(testing_loss_list)/len(testing_loss_list)\n",
    "        torch.save(model.state_dict(),str(epoch))\n",
    "        print('Epoch: {}. Training_Loss: {}.Testing_Loss:{}. Accuracy: {}'.format(epoch, training_loss,test_loss ,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_image.pkl', 'rb') as f:\n",
    "    X = np.array(pickle.load(f),dtype=np.float32)\n",
    "y = F.softmax(model(images))\n",
    "_, predicted = torch.max(y.data, 1)\n",
    "print(predicted)\n",
    "# access Variable's tensor, copy back to CPU, convert to numpy\n",
    "arr = predicted.data.cpu().numpy()\n",
    "arr=np.array(arr,dtype='uint8')\n",
    "final=train_dataset.get_class_labels(arr)\n",
    "# write CSV\n",
    "np.savetxt('output.csv', final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
